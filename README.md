# Классификация персонажей Симпсонов

-------------------------------------------------------------------------------------------------------------------------------------------

## Описание задачи

Целью данного проекта было создание нейросети, способной классифицировать персонажей мультсериала "Симпсоны".

-------------------------------------------------------------------------------------------------------------------------------------------

## Датасет

Исходный датасет (https://www.kaggle.com/datasets/alexattia/the-simpsons-characters-dataset/code) состоял из фотографий размеченных персонажей и был разделен на две части:
- `data/simpsons_dataset/` — тренировочный набор;
- `data/kaggle_simpson_testset/` — тестовый набор.

Для анализа исходных данных я вывела статистику по количеству изображений каждого персонажа в тренировочной и тестовой выборках.

### Распределение данных до изменений:

**Тренировочный датасет** | **Тестовый датасет**  
:-------------------------:|:-------------------------:
![photos BEFORE.png](photos%20BEFORE.png) | ![test_photos BEFORE.png](test_photos%20BEFORE.png)

Анализ показал значительный дисбаланс классов: в некоторых категориях насчитывалось 1–2 тысячи изображений, тогда как в других всего по 3. Это могло привести к тому, что модель не сможет эффективно обучиться на редких классах и не будет обладать обобщающей способностью. Ситуация с тестовым датасетом была ещё хуже: многие классы в нём отсутствовали.

Для устранения дисбаланса я вручную добавила изображения в классы с малым количеством примеров. После этой корректировки распределение стало более равномерным, хотя всё ещё далеким от идеала.

### Распределение данных после изменений:

**Тренировочный датасет** | **Тестовый датасет**  
:-------------------------:|:-------------------------:
![photos AFTER.png](photos%20AFTER.png) | ![test_photos AFTER.png](test_photos%20AFTER.png)

-------------------------------------------------------------------------------------------------------------------------------------------
## Архитектура модели

Для классификации я выбрала предобученную архитектуру **ResNet18**, так как эта модель зарекомендовала себя как эффективная при работе с изображениями. Поскольку ResNet изначально обучена на стандартном наборе классов, я использовала её сверточные слои без изменений, но заменила полносвязный выходной слой, адаптировав его под 42 класса моего датасета.

-------------------------------------------------------------------------------------------------------------------------------------------
## Обучение модели

Изначально я запустила обучение модели на 100 эпох, но вскоре заметила, что функция потерь начала колебаться, указывая на переобучение. Для решения этой проблемы я добавила проверку на валидационной выборке после каждой эпохи.

Было принято решение использовать **раннюю остановку**: если в течение 6 эпох подряд средний loss на валидационных данных не улучшается, обучение завершается. Также для мониторинга процесса обучения я использовала **TensorBoard**.

-------------------------------------------------------------------------------------------------------------------------------------------
## Результаты обучения

Сначала модель обучалась с базовыми преобразованиями (изменение размера до `224x224` и преобразование в тензор). Затем я добавила:
1. **Нормализацию** изображений.
2. **Аугментацию**: случайное горизонтальное отражение и поворот на случайный угол в диапазоне `-30°...30°`.

### Метрики на различных этапах обучения:

[//]: # (![test1.png]&#40;test1.png&#41;)
**Без всего:**



**С нормализацией:**



**С нормализацией и аугментацией:**  



### Примеры выводов модели
![test1.png](test1.png)
![test2.png](test2.png)
![test3.png](test3.png)

### Вывод по графикам

Использование нормализации и аугментации позволило улучшить обобщающую способность модели и повысить качество предсказаний.